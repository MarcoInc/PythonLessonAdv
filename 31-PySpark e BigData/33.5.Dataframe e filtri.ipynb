{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-------+----+----------+-----+\n",
      "| nome|cognome|altezza|peso|   nascita|sesso|\n",
      "+-----+-------+-------+----+----------+-----+\n",
      "|Mario|  Rossi|    1.7|  43|1999-12-25|    M|\n",
      "|Carla|  Verdi|    1.5|  54|1990-08-09|    F|\n",
      "|Marta|Bianchi|   1.75|  82|2000-11-28|    F|\n",
      "|Pippo|   Neri|   1.65|  77|2001-10-07|    M|\n",
      "+-----+-------+-------+----+----------+-----+\n",
      "\n",
      "Filtro -> df.filter(df['sesso']=='F').show()\n",
      "+-----+-------+-------+----+----------+-----+\n",
      "| nome|cognome|altezza|peso|   nascita|sesso|\n",
      "+-----+-------+-------+----+----------+-----+\n",
      "|Carla|  Verdi|    1.5|  54|1990-08-09|    F|\n",
      "|Marta|Bianchi|   1.75|  82|2000-11-28|    F|\n",
      "+-----+-------+-------+----+----------+-----+\n",
      "\n",
      "Filtro alternativo -> df.sesso=='F').show()\n",
      "+-----+-------+-------+----+----------+-----+\n",
      "| nome|cognome|altezza|peso|   nascita|sesso|\n",
      "+-----+-------+-------+----+----------+-----+\n",
      "|Carla|  Verdi|    1.5|  54|1990-08-09|    F|\n",
      "|Marta|Bianchi|   1.75|  82|2000-11-28|    F|\n",
      "+-----+-------+-------+----+----------+-----+\n",
      "\n",
      "Conteggia per categoria -> groupBy('sesso').count().show()\n",
      "+-----+-----+\n",
      "|sesso|count|\n",
      "+-----+-----+\n",
      "|    M|    2|\n",
      "|    F|    2|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import findspark \n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "#Per usare i dataframe si usa SparkSession contenuto in pyspark.sql\n",
    "from pyspark.sql import SparkSession #SparkContext è contentuto in SparkSession\n",
    "from pyspark import SparkContext #usato successivamente per creare il RDD\n",
    "\n",
    "\n",
    "#TRA RDD E DataFrame ci sono due generazioni diverse\n",
    "spark=SparkSession.builder.getOrCreate()\n",
    "dati=[('Mario','Rossi',1.7,43,'1999-12-25','M'),\n",
    "('Carla','Verdi',1.5,54,'1990-08-09','F'),\n",
    "('Marta','Bianchi',1.75,82,'2000-11-28','F'),\n",
    "('Pippo','Neri',1.65,77,'2001-10-07','M')]\n",
    "\n",
    "#creo uno sparkContext\n",
    "sc=spark.sparkContext\n",
    "\n",
    "rdd=sc.parallelize(dati)\n",
    "#Creare un DataFrame da un RDD specificando:\n",
    "    #RDD di partenza\n",
    "    #Nome colonne\n",
    "df=spark.createDataFrame(rdd,['nome','cognome',\n",
    "                                    'altezza','peso','nascita','sesso'])\n",
    "df.show()\n",
    "print(\"Filtro -> df.filter(df['sesso']=='F').show()\")\n",
    "df.filter(df['sesso']=='F').show()\n",
    "#OPPURE\n",
    "print(\"Filtro alternativo -> df.sesso=='F').show()\")\n",
    "df.filter(df.sesso=='F').show()\n",
    "\n",
    "print(\"Conteggia per categoria -> groupBy('sesso').count().show()\")\n",
    "df.groupBy('sesso').count().show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AGGREGAZIONI PERSONALIZZATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-------+----+----------+-----+\n",
      "| nome|cognome|altezza|peso|   nascita|sesso|\n",
      "+-----+-------+-------+----+----------+-----+\n",
      "|Mario|  Rossi|    1.7|  43|1999-12-25|    M|\n",
      "|Carla|  Verdi|    1.5|  54|1990-08-09|    F|\n",
      "|Marta|Bianchi|   1.75|  82|2000-11-28|    F|\n",
      "|Pippo|   Neri|   1.65|  77|2001-10-07|    M|\n",
      "+-----+-------+-------+----+----------+-----+\n",
      "\n",
      "AGGREGAZIONI PERSONALIZZATE -> agg(F....) + groupBy\n",
      "Peso e e altezza media per sesso -> agg(F.mean('peso'),F.mean('altezza')).show()\n",
      "+-----+---------+------------------+\n",
      "|sesso|avg(peso)|      avg(altezza)|\n",
      "+-----+---------+------------------+\n",
      "|    M|     60.0|1.6749999999999998|\n",
      "|    F|     68.0|             1.625|\n",
      "+-----+---------+------------------+\n",
      "\n",
      "Peso e e altezza media per sesso arrotondati -> agg(round(F...),2)\n",
      "+-----+-------------------+----------------------+\n",
      "|sesso|round(avg(peso), 2)|round(avg(altezza), 2)|\n",
      "+-----+-------------------+----------------------+\n",
      "|    M|               60.0|                  1.67|\n",
      "|    F|               68.0|                  1.63|\n",
      "+-----+-------------------+----------------------+\n",
      "\n",
      "ALIAS -> agg(...(F...)).alias('NOME')\n",
      "+-----+----------+-------------+\n",
      "|sesso|peso medio|altezza media|\n",
      "+-----+----------+-------------+\n",
      "|    M|      60.0|         1.67|\n",
      "|    F|      68.0|         1.63|\n",
      "+-----+----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import findspark \n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "#Per usare i dataframe si usa SparkSession contenuto in pyspark.sql\n",
    "from pyspark.sql import SparkSession #SparkContext è contentuto in SparkSession\n",
    "from pyspark import SparkContext #usato successivamente per creare il RDD\n",
    "\n",
    "from pyspark.sql import functions as F \n",
    "\n",
    "#TRA RDD E DataFrame ci sono due generazioni diverse\n",
    "spark=SparkSession.builder.getOrCreate()\n",
    "dati=[('Mario','Rossi',1.7,43,'1999-12-25','M'),\n",
    "('Carla','Verdi',1.5,54,'1990-08-09','F'),\n",
    "('Marta','Bianchi',1.75,82,'2000-11-28','F'),\n",
    "('Pippo','Neri',1.65,77,'2001-10-07','M')]\n",
    "\n",
    "#creo uno sparkContext\n",
    "sc=spark.sparkContext\n",
    "\n",
    "rdd=sc.parallelize(dati)\n",
    "#Creare un DataFrame da un RDD specificando:\n",
    "    #RDD di partenza\n",
    "    #Nome colonne\n",
    "df=spark.createDataFrame(rdd,['nome','cognome',\n",
    "                                    'altezza','peso','nascita','sesso'])\n",
    "df.show()\n",
    "\n",
    "\n",
    "\n",
    "print(\"AGGREGAZIONI PERSONALIZZATE -> agg(F....) + groupBy\")\n",
    "#Per usare funzioni personalizzate per l'aggregazione va importato questo\n",
    "\n",
    "print(\"Peso e e altezza media per sesso -> agg(F.mean('peso'),F.mean('altezza')).show()\")\n",
    "#Mostra il peso medio e altezza media\n",
    "    #groupBy -> raggruppa per sesso\n",
    "    #agg(..)  -> contiene delle funzioni personalizzate\n",
    "    #F -> è l'alias per specificare funzioni\n",
    "df.groupBy('sesso').agg(F.mean('peso'),F.mean('altezza')).show()\n",
    "\n",
    "\n",
    "print(\"Peso e e altezza media per sesso arrotondati -> agg(round(F...),2)\")\n",
    "# round arrotonda i numeri\n",
    "    #2 -> fino alla seconda cifra decimale\n",
    "df.groupBy('sesso').agg(F.round(F.mean('peso'),2),\n",
    "                        F.round(F.mean('altezza'),2)).show()\n",
    "\n",
    "print(\"ALIAS -> agg(...(F...)).alias(\\'NOME\\')\")\n",
    "#dopo aver fatto la media da un ALIAS\n",
    "# ...alias('NUOVO NOME')\n",
    "df.groupBy('sesso').agg(F.round(F.mean('peso'),2).alias('peso medio'),\n",
    "                        F.round(F.mean('altezza'),2).alias('altezza media')).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
